/**
 * ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
 *
 * ë‹¤ì–‘í•œ ì„±ëŠ¥ ì§€í‘œë¥¼ ìˆ˜ì§‘í•˜ê³  Redis/PostgreSQLì— ì €ì¥
 */

import { redis } from '@/lib/cache/redis-client'
import { prisma } from '@/lib/db'

/**
 * ë©”íŠ¸ë¦­ íƒ€ì…
 */
export enum MetricType {
  API = 'api',
  DATABASE = 'database',
  CACHE = 'cache',
  BATCH = 'batch',
  BUSINESS = 'business'
}

/**
 * ë©”íŠ¸ë¦­ ë‹¨ìœ„
 */
export enum MetricUnit {
  MILLISECONDS = 'ms',
  COUNT = 'count',
  PERCENTAGE = 'percentage',
  BYTES = 'bytes'
}

/**
 * ì„±ëŠ¥ ë©”íŠ¸ë¦­
 */
export interface PerformanceMetric {
  timestamp: Date
  metricType: MetricType
  metricName: string
  value: number
  unit: MetricUnit
  tags?: Record<string, string>
}

/**
 * API ë©”íŠ¸ë¦­
 */
export interface APIMetric {
  method: string
  path: string
  statusCode: number
  duration: number
  timestamp: Date
  userId?: string
  clinicId?: string
}

/**
 * ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­
 */
export interface DatabaseMetric {
  operation: string
  table: string
  duration: number
  timestamp: Date
  queryType: 'read' | 'write'
}

/**
 * ìºì‹œ ë©”íŠ¸ë¦­
 */
export interface CacheMetric {
  operation: 'hit' | 'miss' | 'error'
  key: string
  timestamp: Date
}

/**
 * ë©”íŠ¸ë¦­ í‚¤ ìƒì„±
 */
const MetricKeys = {
  // ì‹¤ì‹œê°„ ë°ì´í„° (ìµœê·¼ 5ë¶„)
  realtime: (type: MetricType, name: string) => `metrics:realtime:${type}:${name}`,

  // ë‹¨ê¸° ë°ì´í„° (1ë¶„ ì§‘ê³„, 24ì‹œê°„ ë³´ì¡´)
  shortTerm: (type: MetricType, name: string, timestamp: string) =>
    `metrics:short:${type}:${name}:${timestamp}`,

  // ì¤‘ê¸° ë°ì´í„° (5ë¶„ ì§‘ê³„, 7ì¼ ë³´ì¡´)
  mediumTerm: (type: MetricType, name: string, timestamp: string) =>
    `metrics:medium:${type}:${name}:${timestamp}`,

  // API ì‘ë‹µ ì‹œê°„ ëª©ë¡ (ìµœê·¼ 100ê°œ)
  apiResponseTimes: (path: string) => `metrics:api:times:${path}`,

  // ëŠë¦° ìš”ì²­ ëª©ë¡
  slowRequests: () => `metrics:slow:requests`,

  // ì—ëŸ¬ ì¹´ìš´í„°
  errorCounter: (type: string) => `metrics:errors:${type}`
}

/**
 * ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í´ë˜ìŠ¤
 */
class MetricsCollector {
  /**
   * API ë©”íŠ¸ë¦­ ê¸°ë¡
   */
  async recordAPIMetric(metric: APIMetric): Promise<void> {
    try {
      const { method, path, statusCode, duration, timestamp, userId, clinicId } = metric

      // 1. ì‹¤ì‹œê°„ ë°ì´í„° (ìµœê·¼ 5ë¶„)
      const realtimeKey = MetricKeys.realtime(MetricType.API, 'requests')
      await redis.lpush(realtimeKey, JSON.stringify(metric))
      await redis.ltrim(realtimeKey, 0, 99) // ìµœê·¼ 100ê°œë§Œ ìœ ì§€
      await redis.expire(realtimeKey, 300) // 5ë¶„ TTL

      // 2. ì‘ë‹µ ì‹œê°„ ê¸°ë¡
      const timesKey = MetricKeys.apiResponseTimes(path)
      await redis.lpush(timesKey, duration)
      await redis.ltrim(timesKey, 0, 99)
      await redis.expire(timesKey, 3600) // 1ì‹œê°„ TTL

      // 3. ëŠë¦° ìš”ì²­ (5ì´ˆ ì´ìƒ)
      if (duration > 5000) {
        const slowKey = MetricKeys.slowRequests()
        await redis.zadd(slowKey, {
          score: duration,
          member: JSON.stringify({ method, path, duration, timestamp, userId })
        })
        await redis.zremrangebyrank(slowKey, 0, -51) // ìƒìœ„ 50ê°œë§Œ ìœ ì§€
        await redis.expire(slowKey, 86400) // 24ì‹œê°„ TTL
      }

      // 4. ì—ëŸ¬ ì¹´ìš´í„° (4xx, 5xx)
      if (statusCode >= 400) {
        const errorType = statusCode >= 500 ? '5xx' : '4xx'
        const errorKey = MetricKeys.errorCounter(errorType)
        await redis.incr(errorKey)
        await redis.expire(errorKey, 3600)
      }

      // 5. 1ë¶„ ì§‘ê³„ (ë‹¨ê¸° ë°ì´í„°)
      const minuteTimestamp = this.getMinuteTimestamp(timestamp)
      const shortKey = MetricKeys.shortTerm(MetricType.API, 'avg_duration', minuteTimestamp)
      await redis.lpush(shortKey, duration)
      await redis.expire(shortKey, 86400) // 24ì‹œê°„ TTL
    } catch (error) {
      console.error('Failed to record API metric:', error)
    }
  }

  /**
   * ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­ ê¸°ë¡
   */
  async recordDatabaseMetric(metric: DatabaseMetric): Promise<void> {
    try {
      const { operation, table, duration, timestamp, queryType } = metric

      // ì‹¤ì‹œê°„ ë°ì´í„°
      const realtimeKey = MetricKeys.realtime(MetricType.DATABASE, 'queries')
      await redis.lpush(realtimeKey, JSON.stringify(metric))
      await redis.ltrim(realtimeKey, 0, 99)
      await redis.expire(realtimeKey, 300)

      // ëŠë¦° ì¿¼ë¦¬ (100ms ì´ìƒ)
      if (duration > 100) {
        const slowKey = `metrics:slow:queries`
        await redis.zadd(slowKey, {
          score: duration,
          member: JSON.stringify({ operation, table, duration, timestamp })
        })
        await redis.zremrangebyrank(slowKey, 0, -51)
        await redis.expire(slowKey, 86400)
      }

      // í…Œì´ë¸”ë³„ í†µê³„
      const tableKey = `metrics:db:table:${table}`
      await redis.hincrby(tableKey, queryType, 1)
      await redis.expire(tableKey, 3600)
    } catch (error) {
      console.error('Failed to record database metric:', error)
    }
  }

  /**
   * ìºì‹œ ë©”íŠ¸ë¦­ ê¸°ë¡
   */
  async recordCacheMetric(metric: CacheMetric): Promise<void> {
    try {
      const { operation, key, timestamp } = metric

      // ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ì¹´ìš´í„°
      const counterKey = `metrics:cache:${operation}`
      await redis.incr(counterKey)
      await redis.expire(counterKey, 3600)

      // í‚¤ë³„ í†µê³„
      const keyStatsKey = `metrics:cache:keys:${key}`
      await redis.hincrby(keyStatsKey, operation, 1)
      await redis.expire(keyStatsKey, 3600)
    } catch (error) {
      console.error('Failed to record cache metric:', error)
    }
  }

  /**
   * ë°°ì¹˜ ë©”íŠ¸ë¦­ ê¸°ë¡
   */
  async recordBatchMetric(
    batchType: string,
    duration: number,
    success: boolean,
    details?: Record<string, any>
  ): Promise<void> {
    try {
      const metric = {
        batchType,
        duration,
        success,
        timestamp: new Date(),
        details
      }

      const key = MetricKeys.realtime(MetricType.BATCH, batchType)
      await redis.lpush(key, JSON.stringify(metric))
      await redis.ltrim(key, 0, 49) // ìµœê·¼ 50ê°œ
      await redis.expire(key, 86400)

      // ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´í„°
      const resultKey = `metrics:batch:${batchType}:${success ? 'success' : 'failure'}`
      await redis.incr(resultKey)
      await redis.expire(resultKey, 86400)
    } catch (error) {
      console.error('Failed to record batch metric:', error)
    }
  }

  /**
   * ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ê¸°ë¡
   */
  async recordBusinessMetric(
    metricName: string,
    value: number,
    tags?: Record<string, string>
  ): Promise<void> {
    try {
      const key = MetricKeys.realtime(MetricType.BUSINESS, metricName)
      await redis.lpush(
        key,
        JSON.stringify({
          value,
          timestamp: new Date(),
          tags
        })
      )
      await redis.ltrim(key, 0, 99)
      await redis.expire(key, 3600)
    } catch (error) {
      console.error('Failed to record business metric:', error)
    }
  }

  /**
   * ë©”íŠ¸ë¦­ ì¡°íšŒ - API ì‘ë‹µ ì‹œê°„ í†µê³„
   */
  async getAPIStats(path?: string): Promise<{
    avgDuration: number
    p95Duration: number
    p99Duration: number
    totalRequests: number
    errorRate: number
  }> {
    try {
      const key = path
        ? MetricKeys.apiResponseTimes(path)
        : MetricKeys.realtime(MetricType.API, 'requests')

      const durations = await redis.lrange(key, 0, -1)
      const times = durations.map(d => (typeof d === 'string' ? parseFloat(d) : d)).filter(Boolean)

      if (times.length === 0) {
        return { avgDuration: 0, p95Duration: 0, p99Duration: 0, totalRequests: 0, errorRate: 0 }
      }

      const sorted = times.sort((a, b) => a - b)
      const avg = times.reduce((sum, t) => sum + t, 0) / times.length
      const p95Index = Math.floor(times.length * 0.95)
      const p99Index = Math.floor(times.length * 0.99)

      // ì—ëŸ¬ìœ¨ ê³„ì‚°
      const error4xx = (await redis.get(MetricKeys.errorCounter('4xx'))) || 0
      const error5xx = (await redis.get(MetricKeys.errorCounter('5xx'))) || 0
      const totalErrors = Number(error4xx) + Number(error5xx)
      const errorRate = times.length > 0 ? (totalErrors / times.length) * 100 : 0

      return {
        avgDuration: avg,
        p95Duration: sorted[p95Index] || 0,
        p99Duration: sorted[p99Index] || 0,
        totalRequests: times.length,
        errorRate
      }
    } catch (error) {
      console.error('Failed to get API stats:', error)
      return { avgDuration: 0, p95Duration: 0, p99Duration: 0, totalRequests: 0, errorRate: 0 }
    }
  }

  /**
   * ë©”íŠ¸ë¦­ ì¡°íšŒ - ëŠë¦° ìš”ì²­ Top 10
   */
  async getSlowRequests(limit: number = 10): Promise<any[]> {
    try {
      const key = MetricKeys.slowRequests()
      const slowRequests = await redis.zrange(key, -limit, -1, { rev: true, withScores: true })

      return slowRequests.map((item: any) => {
        try {
          const data = typeof item === 'string' ? JSON.parse(item) : item
          return data
        } catch {
          return null
        }
      }).filter(Boolean)
    } catch (error) {
      console.error('Failed to get slow requests:', error)
      return []
    }
  }

  /**
   * ë©”íŠ¸ë¦­ ì¡°íšŒ - ìºì‹œ í†µê³„
   */
  async getCacheStats(): Promise<{
    hitRate: number
    missRate: number
    errorRate: number
    totalOperations: number
  }> {
    try {
      const hits = Number((await redis.get(MetricKeys.realtime(MetricType.CACHE, 'hit'))) || 0)
      const misses = Number((await redis.get(MetricKeys.realtime(MetricType.CACHE, 'miss'))) || 0)
      const errors = Number((await redis.get(MetricKeys.realtime(MetricType.CACHE, 'error'))) || 0)

      const total = hits + misses + errors

      return {
        hitRate: total > 0 ? (hits / total) * 100 : 0,
        missRate: total > 0 ? (misses / total) * 100 : 0,
        errorRate: total > 0 ? (errors / total) * 100 : 0,
        totalOperations: total
      }
    } catch (error) {
      console.error('Failed to get cache stats:', error)
      return { hitRate: 0, missRate: 0, errorRate: 0, totalOperations: 0 }
    }
  }

  /**
   * í—¬í¼: ë¶„ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
   */
  private getMinuteTimestamp(date: Date): string {
    const d = new Date(date)
    d.setSeconds(0, 0)
    return d.toISOString()
  }

  /**
   * ë©”íŠ¸ë¦­ì„ PostgreSQLì— ì¥ê¸° ì €ì¥ (1ì‹œê°„ ì§‘ê³„)
   */
  async persistMetrics(): Promise<void> {
    try {
      // ì‹¤ì œ êµ¬í˜„: Redisì˜ ì¤‘ê¸° ë°ì´í„°ë¥¼ PostgreSQLë¡œ ì´ë™
      // ë³„ë„ì˜ cron job ë˜ëŠ” scheduled taskë¡œ ì‹¤í–‰
      console.log('ğŸ“Š Persisting metrics to PostgreSQL...')
    } catch (error) {
      console.error('Failed to persist metrics:', error)
    }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const metricsCollector = new MetricsCollector()

/**
 * í¸ì˜ í•¨ìˆ˜
 */
export const recordAPIMetric = (metric: APIMetric) => metricsCollector.recordAPIMetric(metric)
export const recordDatabaseMetric = (metric: DatabaseMetric) =>
  metricsCollector.recordDatabaseMetric(metric)
export const recordCacheMetric = (metric: CacheMetric) => metricsCollector.recordCacheMetric(metric)
export const recordBatchMetric = (
  batchType: string,
  duration: number,
  success: boolean,
  details?: Record<string, any>
) => metricsCollector.recordBatchMetric(batchType, duration, success, details)
export const recordBusinessMetric = (
  metricName: string,
  value: number,
  tags?: Record<string, string>
) => metricsCollector.recordBusinessMetric(metricName, value, tags)
